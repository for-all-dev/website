## What we do

### Papers

- **[Proving the Coding Interview: A Benchmark for Formally Verified Code Generation](https://arxiv.org/abs/2502.05714)** (Dougherty & Mehta, 2025)
  Introduced FVAPPS, the largest formal verification benchmark with 4,715 samples for writing programs and proving their correctness in Lean 4. Presented at LLM4Code Workshop at ICSE 2025.

- **[A benchmark for vericoding: formally verified program synthesis](https://arxiv.org/abs/2509.22908)** (Bursuc et al., 2025)
  The largest benchmark for LLM-generation of formally verified code from formal specifications, with 12,504 samples across Dafny, Verus/Rust, and Lean. Published by Beneficial AI Foundation.

### Organizations

- **[Beneficial AI Foundation (BAIF)](https://baif.ai)** - Contributing to formal verification research and benchmarks for safe AI systems

- **[Galois](https://galois.com)** - Contracting on [ARIA's Mathematics for Safe AI program](https://www.aria.org.uk/opportunity-spaces/mathematics-for-safe-ai), building formal verification capabilities for AI safety

### Comms/movement stuff

- **[Can we secure AI with formal methods?](https://newsletter.for-all.dev)** - Current events newsletter (FKA Progress in Guaranteed Safe AI)
- **[FMxAI 2025](https://sites.google.com/view/fmxai2025)** - Conference on formal methods with machine learning
- **[Cookbook](https://recipes.for-all.dev)** - formal verification agent recipes, an ebook.
